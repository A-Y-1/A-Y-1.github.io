<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>NEON编程 | 橙的Blog</title><meta name="author" content="橙"><meta name="copyright" content="橙"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原书为Arm的NEON Programmer’s Guide和NEON Programmer Guide for Armv8-A。">
<meta property="og:type" content="article">
<meta property="og:title" content="NEON编程">
<meta property="og:url" content="https://a-y-1.github.io/2024/01/02/Neon/index.html">
<meta property="og:site_name" content="橙的Blog">
<meta property="og:description" content="原书为Arm的NEON Programmer’s Guide和NEON Programmer Guide for Armv8-A。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://a-y-1.github.io/cover/NEON.png">
<meta property="article:published_time" content="2024-01-02T12:19:29.000Z">
<meta property="article:modified_time" content="2024-01-05T07:54:32.205Z">
<meta property="article:author" content="橙">
<meta property="article:tag" content="高性能计算">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://a-y-1.github.io/cover/NEON.png"><link rel="shortcut icon" href="/img/orange.png"><link rel="canonical" href="https://a-y-1.github.io/2024/01/02/Neon/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'NEON编程',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2024-01-05 15:54:32'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="APlayer.min.css"><div id="aplayer"></div><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js" async></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/a0.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/../cover/0105.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="橙的Blog"><span class="site-name">橙的Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">NEON编程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-02T12:19:29.000Z" title="发表于 2024-01-02 20:19:29">2024-01-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-05T07:54:32.205Z" title="更新于 2024-01-05 15:54:32">2024-01-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="NEON编程"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p> 原书为Arm的NEON Programmer’s Guide和NEON Programmer Guide for Armv8-A。</p>
<span id="more"></span>
<h2 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 Introduction"></a>Chapter 1 Introduction</h2><h3 id="1-1-Data-processing-technologies"><a href="#1-1-Data-processing-technologies" class="headerlink" title="1.1 Data processing technologies"></a>1.1 Data processing technologies</h3><p>数据处理的常见方法有SISD，SIMD(vector mode)，SIMD(packed data mode)。</p>
<p><strong>vector mode</strong></p>
<p>假设vector size为4，SIMD(vector)可使用单指令完成4个数据的操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">VADD.F32 S24, S8, S16</span><br><span class="line">// four operations occur</span><br><span class="line">// S24 = S8 +S16</span><br><span class="line">// S25 = S9 +S17</span><br><span class="line">// S26 = S10 +S18</span><br><span class="line">// S27 = S11 +S20</span><br></pre></td></tr></table></figure>
<p>在ARM中，这称为<strong>Vector Floating Point(VFP)</strong>，在ARMv5引入，源和目标寄存器既可以是单个寄存器也可以是多个寄存器。在ARMv7，NEON代替了VFP实现多寄存器上的操作。</p>
<p><strong>packed data mode</strong></p>
<p>这种模式下，一个指令可以指定一个大寄存器中的多个数据部分进行相同的处理：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">VADD.I16 Q10, Q8, Q9</span><br><span class="line">// One operation adds two 64-bit registers,</span><br><span class="line">// but each of the four 16-bit lanes in the register is added separately.</span><br><span class="line">// There are no carries between the lanes</span><br></pre></td></tr></table></figure>
<p>在ARM中，这称为SIMD或NEON。</p>
<h3 id="1-2-Comparison-between-ARM-NEON-technology-and-other-implementations"><a href="#1-2-Comparison-between-ARM-NEON-technology-and-other-implementations" class="headerlink" title="1.2 Comparison between ARM NEON technology and other implementations"></a>1.2 Comparison between ARM NEON technology and other implementations</h3><p>与ARMv6中相比，ARM NEON的计算单元支持128-bit的向量操作，在ARMv6中只有32-bit的向量操作。并且在NEON中，这些寄存器是单独的，并且其向量操作是专门优化过的，而ARMv6中只是使用和其他指令相同的寄存器和流水线。</p>
<p>与X86的MMX/SSE的比较以及与DSP的比较这里略去了。</p>
<h3 id="1-3-Architecture-support-for-NEON-technology"><a href="#1-3-Architecture-support-for-NEON-technology" class="headerlink" title="1.3 Architecture support for NEON technology"></a>1.3 Architecture support for NEON technology</h3><ul>
<li>不能保证ARMv7-A或ARMv7-R处理器包含NEON或VFP技术。</li>
<li>ARMv7核心的可能组合包括没有NEON或VFP单元，仅有NEON单元，仅有VFP单元或同时具有NEON和VFP单元。</li>
<li>具有NEON单元但没有VFP单元的处理器无法在硬件中执行浮点运算。</li>
<li>由于NEON SIMD操作更有效地执行矢量计算，从ARMv7引入开始，VFP矢量模式操作被弃用。</li>
<li>VFP单元有时被称为浮点单元（FPU）。</li>
<li>具有NEON或VFP单元的处理器可能不支持某些扩展，如半精度和融合乘加。</li>
</ul>
<ul>
<li>半精度指令仅在包含半精度扩展的NEON和VFP系统上可用。</li>
<li>Fused Multiply-Add (FMA)指令是对VFP和NEON的可选扩展。仅在实现了Fused Multiply-Add扩展的NEON或VFP系统上才可用。VFPv4和Advanced SIMDv2支持Fused Multiply-Add指令。</li>
</ul>
<h3 id="1-4-Fundamentals-of-NEON-technology"><a href="#1-4-Fundamentals-of-NEON-technology" class="headerlink" title="1.4 Fundamentals of NEON technology"></a>1.4 Fundamentals of NEON technology</h3><p>NEON单元的组成部分包括：</p>
<ul>
<li>NEON寄存器文件</li>
<li>NEON整数执行流水线</li>
<li>NEON单精度浮点执行流水线</li>
<li>NEON加载/存储和置换流水线。</li>
</ul>
<p>NEON指令和浮点指令使用相同的寄存器文件，称为NEON和浮点寄存器文件。这与ARM核心寄存器文件不同。NEON和浮点寄存器文件是一组可被访问为32位、64位或128位寄存器的寄存器的集合。哪个寄存器可用于指令取决于它是NEON指令还是VFP指令。本文将NEON和浮点寄存器称为NEON寄存器。某些VFP和NEON指令在通用寄存器和NEON寄存器之间移动数据，或使用ARM通用寄存器来寻址内存。</p>
<p><img src="/2024/01/02/Neon/image-20240102210351577.png" alt="image-20240102210351577" style="zoom: 33%;"></p>
<p><img src="/2024/01/02/Neon/image-20240102210425127.png" alt="image-20240102210425127" style="zoom:33%;"></p>
<p>Arm v8 AArch64有32个128位寄存器，也能当作32位Sn寄存器或是64位Dn寄存器使用。</p>
<p>一些NEON指令会使用标量，标量可以通过下标表示。例如VMOV.8 D0[3], R3。NEON标量可以是8bit，16bit，32bit或64bit，除了乘法指令，其他指令都可以访问寄存器中的任意位标量，乘法只能访问：</p>
<ul>
<li>16bit标量：D0-D7的[0-3]</li>
<li>32bit标量：D0-D15的[0-1]</li>
</ul>
<p>NEON中的数据类型：</p>
<p><img src="/2024/01/02/Neon/image-20240102211912523.png" alt="image-20240102211912523" style="zoom: 50%;"></p>
<h2 id="Chapter-2-Compiling-NEON-Instructions"><a href="#Chapter-2-Compiling-NEON-Instructions" class="headerlink" title="Chapter 2 Compiling NEON Instructions"></a>Chapter 2 Compiling NEON Instructions</h2><p>要使用GCC进行自动向量化，需要添加以下选项：</p>
<ul>
<li>-ftree-vectorize</li>
<li>-mfpu=neon</li>
<li>-mcpu 指定核或架构</li>
</ul>
<p>以-O3编译相当于添加了-ftree-vectorize。</p>
<p>通常，如果不采用自动向量化，一般使用INTRINSIC代码嵌入C中来使用NEON。需要在头文件中包含<code>arm_neon.h</code>，并指定处理器类型，例如<code>-mcpu=cortex-a72</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arm_neon.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_float_arrays</span><span class="params">(<span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">float</span> *c, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// assume n is a multiple of 4</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i += <span class="number">4</span>) &#123;</span><br><span class="line">    <span class="comment">// load 4 floats from a and b into NEON registers</span></span><br><span class="line">    <span class="type">float32x4_t</span> va = <span class="built_in">vld1q_f32</span>(a + i);</span><br><span class="line">    <span class="type">float32x4_t</span> vb = <span class="built_in">vld1q_f32</span>(b + i);</span><br><span class="line">    <span class="comment">// add the vectors</span></span><br><span class="line">    <span class="type">float32x4_t</span> vc = <span class="built_in">vaddq_f32</span>(va, vb);</span><br><span class="line">    <span class="comment">// store the result into c</span></span><br><span class="line">    <span class="built_in">vst1q_f32</span>(c + i, vc);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>C pointer aliasing</strong></p>
<p>标准C中，指针可能指向相同或重叠的数据，这给优化带来了困难。C99和C++引入了restrict关键字，用于声明指针的唯一性，从而提高编译器的优化能力。ARM编译器和GCC都支持restrict关键字，但有不同的语法和选项。</p>
<p><strong>Natural types</strong></p>
<p>算法使用特定数据类型有其原因，但转换为处理器自然类型可以提高运算速度和精度。</p>
<p><strong>Array grouping</strong></p>
<p>对于寄存器数量较少的处理器设计（如x86），通常会将多个数组合并为一个。这样可以让同一个指针的不同偏移量访问数据的不同部分。但是这种方式可能会让编译器误认为偏移量导致了数据集的重叠。除非可以保证不会对数组进行写入操作，否则请避免这样做。将复合数组拆分为单独的数组，可以简化指针的使用并消除这种风险。</p>
<p><strong>Inside knowledge</strong></p>
<p>NEON代码需要知道数组大小，否则编译器会生成多余的代码。数组大小可以在编译时指定，也可以根据工程师的知识进行优化。</p>
<h2 id="Chapter-3-coding-for-NEON"><a href="#Chapter-3-coding-for-NEON" class="headerlink" title="Chapter 3 coding for NEON"></a>Chapter 3 coding for NEON</h2><h3 id="3-1-Overview"><a href="#3-1-Overview" class="headerlink" title="3.1 Overview"></a>3.1 Overview</h3><p>这份guide包含以下内容：</p>
<ul>
<li>Memory operations, and how to use the flexible load and store instructions. </li>
<li>Using the permutation instructions to deal with load and store leftovers. </li>
<li>Using NEON to perform an example data processing task, matrix multiplication. </li>
<li>Shifting operations, using the example of converting image data formats.</li>
</ul>
<h3 id="3-2-Load-and-store-example-RGB-conversion"><a href="#3-2-Load-and-store-example-RGB-conversion" class="headerlink" title="3.2 Load and store - example RGB conversion"></a>3.2 Load and store - example RGB conversion</h3><p>本节以RGB到BGR的转换为例。在一个24bit的RGB图中，像素在内存中以R G B R G B的模式存储。假设现在要完成一个简单的图像处理，交换R和B channel。将RGB数据项按顺序从内存放入寄存器会使交换红色和蓝色通道难以操作。</p>
<p>以下指令将RGB data每次一字节存入NEON寄存器：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LD1 &#123; V0.16B, V1.16B, V2.16B &#125;, [x0]</span><br></pre></td></tr></table></figure>
<p><img src="/2024/01/02/Neon/image-20240104151616427.png" alt="image-20240104151616427" style="zoom: 50%;"></p>
<p>这种情况下，交换不同的Lane会比较复杂。NEON提供了结构load和store指令来应对这种情况，可以将连续的数据分别存储到不同的寄存器。在这个例子中，可以使用LD3指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LD3 &#123; V0.16B, V1.16B, V2.16B &#125;, [x0]</span><br></pre></td></tr></table></figure>
<p><img src="/2024/01/02/Neon/image-20240104151905763.png" alt="image-20240104151905763" style="zoom:50%;"></p>
<p>这样只需要使用MOV指令对整个Vector交换，然后使用ST3 store指令写回，完整的操作如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">LD3 &#123; V0.16B, V1.16B, V2.16B &#125;, [x0], #48 // 3-way interleaved load from</span><br><span class="line"> // address in X0, post-incremented</span><br><span class="line"> // by 48</span><br><span class="line">MOV V3.16B, V0.16B // Swap V0 -&gt; V3</span><br><span class="line">MOV V0.16B, V2.16B // Swap V2 -&gt; V0</span><br><span class="line">MOV V2.16B, V3.16B // Swap V3 -&gt; V2</span><br><span class="line"> // (net effect is to swap V0 and V2)</span><br><span class="line">ST3 &#123; V0.16B, V1.16B, V2.16B &#125;, [x1], #48 // 3-way interleaved store to address</span><br><span class="line"> // in X1, post-incremented by 48</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>每一步的操作如下：</p>
<ul>
<li>Loads from memory 16 red bytes into V0, 16 green bytes into V1, and 16 blue bytes into V2. </li>
<li>Increments the source pointer in X0 by 48 bytes ready for the next iteration. The increment of 48 bytes is the total number of bytes that we read into all three registers, so 3 x 16 bytes in total. </li>
<li>Swaps the vector of red values in V0 with the vector of blue values in V2, using V3 as an intermediary. </li>
<li>Stores the data in V0, V1, and V2 to memory, starting at the address that is specified by the destination pointer in X1, and increments the pointer.</li>
</ul>
<h3 id="3-3-Load-and-store-data-structures"><a href="#3-3-Load-and-store-data-structures" class="headerlink" title="3.3 Load and store - data structures"></a>3.3 Load and store - data structures</h3><p>在上一个例子中提到的指令进行的操作如下图：</p>
<p><img src="/2024/01/02/Neon/image-20240104152831778.png" alt="image-20240104152831778" style="zoom:50%;"></p>
<p>指令的语法如下：</p>
<p><img src="/2024/01/02/Neon/image-20240104152856011.png" alt="image-20240104152856011" style="zoom:50%;"></p>
<p>其中的Registers根据interleave pattern最多可以有四个，后面的16B表示每个数据是1B(byte)，每个向量是128bit，存储16B。数据类型有8(B)，16(H)，32(S)，64(D)bits。</p>
<p>以下是两个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LD2 &#123;V0.8H, V1.8H&#125;, [X0]</span><br><span class="line">LD2 &#123;V0.4S, V1.4S&#125;, [X0]</span><br></pre></td></tr></table></figure>
<p><img src="/2024/01/02/Neon/image-20240104153412464.png" alt="image-20240104153412464" style="zoom: 33%;"></p>
<p><img src="/2024/01/02/Neon/image-20240104153437456.png" alt="image-20240104153437456" style="zoom:33%;"></p>
<p>structure load还允许加载一个元素到vector的所有lane中，如下指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LD3R &#123; V0.16B, V1.16B, V2.16B &#125; , [x0]</span><br></pre></td></tr></table></figure>
<p><img src="/2024/01/02/Neon/image-20240104153841418.png" alt="image-20240104153841418" style="zoom: 50%;"></p>
<p>也可以只load到一个lane当中，这在从存储中获取分散的数据到vector中很有用：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LD3 &#123; V0.B, V1.B, V2.B &#125;[4] , [x0]</span><br></pre></td></tr></table></figure></p>
<p><img src="/2024/01/02/Neon/image-20240104154024393.png" alt="image-20240104154024393" style="zoom:50%;"></p>
<p>[]可以指定地址偏移。为了方便下一次读写，指令后可以添加#imm，会直接给x0地址的值+imm。</p>
<p>除了上述的structure load and store，NEON也提供其他类型的LD和ST指令，详见Arm Architecture Reference Manual。</p>
<h3 id="3-4-Load-and-store-leftovers"><a href="#3-4-Load-and-store-leftovers" class="headerlink" title="3.4 Load and store - leftovers"></a>3.4 Load and store - leftovers</h3><p>有时输入数据不是向量寄存器lanes的整数倍。例如一个输入数组有21个16bit的元素。NEON寄存器可以一次处理8个元素，最后一次迭代只有5个元素，这5个元素无法填满寄存器。</p>
<p>有三种处理这种情况的办法，需要根据情况选择：</p>
<ul>
<li>Extend arrays with padding</li>
<li>Overlap data elements</li>
<li>Process leftovers as single elements</li>
</ul>
<p><strong>Extend arrays with padding</strong></p>
<p>如果数组长度可变，可以将其填充到vector size的倍数，这样就可以在不影响其他数据的情况下进行数据读写。padding值应该不影响计算的结果。</p>
<p><img src="/2024/01/02/Neon/image-20240104161852536.png" alt="image-20240104161852536" style="zoom:50%;"></p>
<p><strong>Overlap data elements</strong></p>
<p>如果操作合适，可以通过重叠元素处理多出来的元素。</p>
<p><img src="/2024/01/02/Neon/image-20240104162820857.png" alt="image-20240104162820857" style="zoom:50%;"></p>
<p><strong>Process leftovers as single elements</strong></p>
<p>NEON提供了可对向量中的单个元素操作的指令，最后的元素可以单独进行处理。这种方式比前两种都慢，并且会增加代码规模。 </p>
<p>还有一些其他需要关注的点：</p>
<ul>
<li>地址对齐：load and store指令的地址应该和缓存行的大小对齐，以实现更高效的访存。</li>
<li>可以使用A64的指令完成单独元素的的计算，但是要NEON和A64指令写入相同的内存，特别是相同的cache line。</li>
</ul>
<h3 id="3-5-Permutation-rearranging-vectors"><a href="#3-5-Permutation-rearranging-vectors" class="headerlink" title="3.5 Permutation - rearranging vectors"></a>3.5 Permutation - rearranging vectors</h3><p>在编写SIMD程序时，数据的顺序很重要，与性能直接相关，有时数据在内存中的位置可能不合适或不是最优的。</p>
<p>一个解决上述问题的方法是重新安排数据。这种方式的性能开销很高。更好的办法是在数据被处理时重新安排数据，重安排被称为permutation，NEON提供了一系列permute指令，实现以下操作：</p>
<ul>
<li>Take input data from one or more source registers</li>
<li>Rearrange the data</li>
<li>Write the result of the permutation to a destination register</li>
</ul>
<p><strong>Permutation guidelines</strong></p>
<ul>
<li>permuting data不是什么时候都有用。</li>
<li>permute指令会带来开销。</li>
<li>不同的指令使用不同的pipline。最优的方法是最大化pipline的使用。因此需要尽量少使用permute操作，选择执行时会利用空闲pipline的指令。</li>
</ul>
<h3 id="3-6-Permutation-NEON-instructions"><a href="#3-6-Permutation-NEON-instructions" class="headerlink" title="3.6 Permutation - NEON instructions"></a>3.6 Permutation - NEON instructions</h3><p>这一节介绍的permute指令包括：</p>
<ul>
<li>Move</li>
<li>Reverse</li>
<li>Extraction</li>
<li>Transpose</li>
<li>Interleave</li>
<li>Lookup table</li>
</ul>
<p>这里不一一说明这些指令了，需要时再查询。</p>
<h3 id="3-7-Matrix-multiplication"><a href="#3-7-Matrix-multiplication" class="headerlink" title="3.7 Matrix multiplication"></a>3.7 Matrix multiplication</h3><p>这一节是NEON实现矩阵乘法的例子。假定矩阵按照列顺序存储(OpenGL ES的存储格式)。每次计算4*4的矩阵。</p>
<p><img src="/2024/01/02/Neon/image-20240104165307145.png" alt="image-20240104165307145"></p>
<p>下图显示了使用NEON的FMUL指令实现向量和标量的相乘：</p>
<p><img src="/2024/01/02/Neon/image-20240104165519702.png" alt="image-20240104165519702" style="zoom: 80%;"></p>
<p>对应矩阵的计算为：</p>
<p><img src="/2024/01/02/Neon/image-20240104165611277.png" alt="image-20240104165611277"></p>
<p>NEON寄存器可以按照不同的格式存储数据，如下图：</p>
<p><img src="/2024/01/02/Neon/image-20240104165731965.png" alt="image-20240104165731965" style="zoom: 50%;"></p>
<p>矩阵乘法分三步完成：</p>
<ul>
<li>Load矩阵数据</li>
<li>矩阵乘法</li>
<li>存储结果</li>
</ul>
<p>load数据的指令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LD1 &#123;V0.4S, V1.4S, V2.4S, V3.4S&#125;, [X1]</span><br><span class="line">LD1 &#123;V4.4S, V5.4S, V6.4S, V7.4S&#125;, [X2]</span><br></pre></td></tr></table></figure>
<p>NEON提供32个128bit宽的寄存器。在这个实现中，V0-V3存储了第一个矩阵的16个元素，V4-V7存储了第二个矩阵的16个元素。每个寄存器存储一个矩阵行。</p>
<p>以下代码计算一列的结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FMUL V8.4S, V0.4S, V4.S[0] // rslt col0 = (mat0 col0) * (mat1 col0 elt0)</span><br><span class="line">FMLA V8.4S, V1.4S, V4.S[1] // rslt col0 += (mat0 col1) * (mat1 col0 elt1)</span><br><span class="line">FMLA V8.4S, V2.4S, V4.S[2] // rslt col0 += (mat0 col2) * (mat1 col0 elt2)</span><br><span class="line">FMLA V8.4S, V3.4S, V4.S[3] // rslt col0 += (mat0 col3) * (mat1 col0 elt3)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>完整的矩阵运算代码就略去了。只要按照以上代码计算每一列就可以了。每一列要四条指令，将其进行交错，可以提高流水线的ILP。</p>
<h3 id="3-8-Shifting-left-and-right"><a href="#3-8-Shifting-left-and-right" class="headerlink" title="3.8 Shifting left and right"></a>3.8 Shifting left and right</h3><p>本节介绍了NEON提供的shift操作。</p>
<p>NEON的向量shift和标量的操作很类似，将元素中的位左移或右移，移出的位会被舍弃，不会移到相邻的位置。移位数可以是指令指定的，也可以是一个移位向量。</p>
<p>下图是NEON的SSHL指令，V1是移位向量：</p>
<p><img src="/2024/01/02/Neon/image-20240104173138848.png" alt="image-20240104173138848"></p>
<p>在右移位操作时，要考虑处理的是有符号还是无符号的数据。SSHL是有符号的shift操作。相应的USHL是无符号的。</p>
<p>NEON还支持插入shift，如下图的SLI指令：</p>
<p><img src="/2024/01/02/Neon/image-20240104173449521.png" alt="image-20240104173449521"></p>
<p>此后是shift指令的一些其他可选项的介绍，以及一个例子，这里都略去了。</p>
<h2 id="Chapter-4-NEON-Intrinsics"><a href="#Chapter-4-NEON-Intrinsics" class="headerlink" title="Chapter 4 NEON Intrinsics"></a>Chapter 4 NEON Intrinsics</h2><h3 id="4-1-Overview"><a href="#4-1-Overview" class="headerlink" title="4.1 Overview"></a>4.1 Overview</h3><p>NEON Intrinsics提供了简单的NEON指令编写方式。有符合NEON的数据类型(D和Q寄存器的大小都有)，可以使用C变量来分配NEON寄存器。由编译器生成具体的代码。编译器也会进行优化，进行指令重排序来减少停顿，提高ILP。</p>
<p>NEON intrinsic的定义在<code>arm_neon.h</code>中。</p>
<h3 id="4-2-Vector-data-types-for-NEON-intrinsics"><a href="#4-2-Vector-data-types-for-NEON-intrinsics" class="headerlink" title="4.2 Vector data types for NEON intrinsics"></a>4.2 Vector data types for NEON intrinsics</h3><p>数据类型的pattern如下：</p>
<p>type    size    x    numberOfLanes    _t</p>
<p>例如int16x4_t是一个有4个16bit的short int的向量。float32x4_t是有4个32-bit浮点的向量。</p>
<p><img src="/2024/01/02/Neon/image-20240105150025326.png" alt="image-20240105150025326" style="zoom:50%;"></p>
<p>intrinsics的输入和输出可以是这些类型。有些intrinsics使用向量元素构成的数组，包含2,3,4个相同的向量元素，这样的类型为：</p>
<p>type    size    x    numberOfLanes    x    lengthOfArray    _t</p>
<p>这些类型是C结构体，包含一个val的数组。这样的类型可以通过NEON的指令一次加载或存储4个向量寄存器的值。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">int16x4x2_t</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"> <span class="type">int16x4_t</span> val[<span class="number">2</span>];</span><br><span class="line">&#125; &lt;var_name&gt;;</span><br></pre></td></tr></table></figure>
<p>这些类型只能使用load，store，transpose，interleave，deinterleave指令。可以通过下标访问单个寄存器，例如var_name.val[0]。</p>
<p>🔰initialize：vector data type不能赋值初始化，可以使用load指令初始化或使用vcreate intrinsic初始化。</p>
<h3 id="4-3-Prototype-of-NEON-Intrinsics"><a href="#4-3-Prototype-of-NEON-Intrinsics" class="headerlink" title="4.3 Prototype of NEON Intrinsics"></a>4.3 Prototype of NEON Intrinsics</h3><p>NEON intrinsics的指令格式如下：</p>
<p>opname    flags_type</p>
<p>例如：</p>
<ul>
<li>vmul_s16，将两个含16bit signed的向量相乘</li>
<li>vaddl_u8，将两个存储unsigned 8bit值的64bit向量相加，得到128bit的存储unsigned 16bit向量</li>
</ul>
<p>flag可以取q，表示计算操作是针对128bit向量的。</p>
<p>🔰Note：含有__fp16的指令只用于支持半精度扩展VFP的架构。</p>
<h3 id="4-4-Using-NEON-intrinsics"><a href="#4-4-Using-NEON-intrinsics" class="headerlink" title="4.4 Using NEON intrinsics"></a>4.4 Using NEON intrinsics</h3><p>intrinsics含q的表示在Q寄存器操作，不含q的表示在D寄存器操作。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uint8x8_t vadd_u8(uint8x8_t a, uint8x8_t b); #64bit</span><br><span class="line">uint8x16_t vaddq_u8(uint8x16_t a, uint8x16_t b); #128bit</span><br></pre></td></tr></table></figure>
<p>有些指令没有q后缀，也是会使用Q寄存器的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uint16x8_t vaddl_u8(uint8x8_t a, uint8x8_t b);</span><br></pre></td></tr></table></figure>
<p>一些NEON intrinsics指令会使用32bit的通用寄存器作为输入存储标量。例如以下这一些指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vget_lane_u8 #get single value</span><br><span class="line">vset_lane_u8 #set single value </span><br><span class="line">vcreate_u8 #create vector from literal value</span><br><span class="line">vdup_n_u8 #set all lanes to the same literal value</span><br></pre></td></tr></table></figure>
<p>使用intrinsics时，使用不同的类型操作会比较困难，因为编译器会跟踪寄存器存储的类型。寄存器也会调度程序流及调整程序加快执行。</p>
<p>以下是一个将4lane 32bit向量元素翻倍的例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arm_neon.h&gt;</span></span></span><br><span class="line"><span class="type">uint32x4_t</span> <span class="title function_">double_elements</span><span class="params">(<span class="type">uint32x4_t</span> input)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span>(vaddq_u32(input, input));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="4-5-Variables-and-constants-in-NEON-code"><a href="#4-5-Variables-and-constants-in-NEON-code" class="headerlink" title="4.5 Variables and constants in NEON code"></a>4.5 Variables and constants in NEON code</h3><p>这一节主要是一些example code：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//declaring variable</span></span><br><span class="line"><span class="type">uint32x2_t</span> vec64a, vec64b;</span><br><span class="line"><span class="comment">//using constants</span></span><br><span class="line">uint8x8 start_value = vdup_n_u8(<span class="number">0</span>);</span><br><span class="line">uint8x8 start_value = vreinterpret_u8_u64(vcreate_u64(<span class="number">0x123456789ABCDEF</span>ULL));</span><br><span class="line"><span class="comment">//moving results back to C variables get_lane0/VST store to memory</span></span><br><span class="line">result = vget_lane_u32(vec64a, <span class="number">0</span>);</span><br><span class="line"><span class="comment">//Accessing D registers from a Q register</span></span><br><span class="line">vec64a = vget_low_u32(vec128); <span class="comment">// split 128-bit vector </span></span><br><span class="line">vec64b = vget_high_u32(vec128); <span class="comment">// into 2x 64-bit vectors</span></span><br><span class="line"><span class="comment">//Casting NEON variables between different types</span></span><br><span class="line"><span class="type">uint8x8_t</span> byteval;</span><br><span class="line"><span class="type">uint32x2_t</span> wordval;</span><br><span class="line">byteval = vreinterpret_u8_u32(wordval);</span><br><span class="line"><span class="type">uint8x16_t</span> byteval2;</span><br><span class="line"><span class="type">uint32x4_t</span> wordval2;</span><br><span class="line">byteval2 = vreinterpretq_u8_u32(wordval2)</span><br></pre></td></tr></table></figure>
<h3 id="4-6-Accessing-vector-types-from-C"><a href="#4-6-Accessing-vector-types-from-C" class="headerlink" title="4.6 Accessing vector types from C"></a>4.6 Accessing vector types from C</h3><p>C中的数据格式正如上述，写为uint8x16_t或者int16x4_t这样的类型。标量和vector之间必须通过intrinsics指令处理，例如result = vget_lane_u32(vec64a, 0)。</p>
<h3 id="4-7-Loading-data-from-memory-into-vectors"><a href="#4-7-Loading-data-from-memory-into-vectors" class="headerlink" title="4.7 Loading data from memory into vectors"></a>4.7 Loading data from memory into vectors</h3><p>intrinsics使用vld1_datatype加载连续的数据，以下是一段示例代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arm_neon.h&gt;</span></span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">short</span> <span class="type">int</span> A[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;; <span class="comment">// array with 4 elements</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="type">uint16x4_t</span> v; <span class="comment">// declare a vector of four 16-bit lanes</span></span><br><span class="line">    v = vld1_u16(A); <span class="comment">// load the array from memory into a vector</span></span><br><span class="line">    v = vadd_u16(v,v); <span class="comment">// double each element in the vector</span></span><br><span class="line">    vst1_u16(A, v); <span class="comment">// store the vector back to memory</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-8-Constructing-a-vector-from-a-literal-bit-pattern"><a href="#4-8-Constructing-a-vector-from-a-literal-bit-pattern" class="headerlink" title="4.8 Constructing a vector from a literal bit pattern"></a>4.8 Constructing a vector from a literal bit pattern</h3><p>NEON intrinsics通过vcreate_datatype来从常量值创建向量，以下是一段示例代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arm_neon.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span> <span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="type">uint8x8_t</span> v; <span class="comment">// define v as a vector with 8 lanes of 8-bit data</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> A[<span class="number">8</span>]; <span class="comment">// allocate memory for eight 8-bit data</span></span><br><span class="line">    v = vcreate_u8(<span class="number">0x0102030405060708</span>); <span class="comment">// create a vector that contains the values</span></span><br><span class="line">    <span class="comment">// 1,2,3,4,5,6,7,8</span></span><br><span class="line">    vst1_u8(A, v); <span class="comment">// store the vector to memory, in this case, to array A</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-9-Constructing-multiple-vectors-from-interleaved-memory"><a href="#4-9-Constructing-multiple-vectors-from-interleaved-memory" class="headerlink" title="4.9  Constructing multiple vectors from interleaved memory"></a>4.9  Constructing multiple vectors from interleaved memory</h3><p>NEON支持交错load数据。交错模式由n指定，指令为vldn_datatype，正如在第三章介绍的那样。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arm_neon.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span> <span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="type">uint8x8x3_t</span> v; <span class="comment">// This represents 3 vectors. </span></span><br><span class="line">    <span class="comment">// Each vector has eight lanes of 8-bit data.</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> A[<span class="number">24</span>]; <span class="comment">// This array represents a 24-bit RGB image. </span></span><br><span class="line">    v = vld3_u8(A); <span class="comment">// This de-interleaves the 24-bit image from array A </span></span><br><span class="line">    <span class="comment">// and stores them in 3 separate vectors</span></span><br><span class="line">    <span class="comment">// v.val[0] is the first vector in V. It is for the red channel</span></span><br><span class="line">    <span class="comment">// v.val[1] is the second vector in V. It is for the green channel</span></span><br><span class="line">    <span class="comment">// v.val[2] is the third vector in V. It is for the blue channel.</span></span><br><span class="line">    <span class="comment">//Double the red channel</span></span><br><span class="line">    v.val[<span class="number">0</span>] = vadd_u8(v.val[<span class="number">0</span>],v.val[<span class="number">0</span>]);</span><br><span class="line">    vst3_u8(A, v); <span class="comment">// store the vector back into the array, with the red channel doubled.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-10-Programming-using-NEON-intrinsics"><a href="#4-10-Programming-using-NEON-intrinsics" class="headerlink" title="4.10 Programming using NEON intrinsics"></a>4.10 Programming using NEON intrinsics</h3><p>NEON编程需要考虑到算法怎样能够实现并行，以下是一个计算数组和的例子，假设n是4的倍数。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;arm_neon.h&gt;</span></span></span><br><span class="line"><span class="type">uint32_t</span> <span class="title function_">vector_add_of_n</span><span class="params">(<span class="type">uint32_t</span>* ptr, <span class="type">uint32_t</span> items)</span>&#123;</span><br><span class="line">    <span class="type">uint32_t</span> result,* i;</span><br><span class="line">    <span class="type">uint32x2_t</span> vec64a, vec64b;</span><br><span class="line">    <span class="type">uint32x4_t</span> vec128 = vdupq_n_u32(<span class="number">0</span>); <span class="comment">// clear accumulators</span></span><br><span class="line">    <span class="keyword">for</span> (i=ptr; i&lt;(ptr+(items/<span class="number">4</span>));i+=<span class="number">4</span>)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="type">uint32x4_t</span> temp128 = vld1q_u32(i); <span class="comment">// load four 32-bit values</span></span><br><span class="line">    vec128=vaddq_u32(vec128, temp128); <span class="comment">// add 128-bit vectors</span></span><br><span class="line">    &#125;</span><br><span class="line">    vec64a = vget_low_u32(vec128); <span class="comment">// split 128-bit vector</span></span><br><span class="line">    vec64b = vget_high_u32(vec128); <span class="comment">// into two 64-bit vectors</span></span><br><span class="line">    vec64a = vadd_u32 (vec64a, vec64b); <span class="comment">// add 64-bit vectors together</span></span><br><span class="line">    result = vget_lane_u32(vec64a, <span class="number">0</span>); <span class="comment">// extract lanes and</span></span><br><span class="line">    result += vget_lane_u32(vec64a, <span class="number">1</span>); <span class="comment">// add together scalars</span></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://a-y-1.github.io">橙</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://a-y-1.github.io/2024/01/02/Neon/">https://a-y-1.github.io/2024/01/02/Neon/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://a-y-1.github.io" target="_blank">橙的Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a></div><div class="post_share"><div class="social-share" data-image="/../cover/NEON.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/01/06/HPC-Game/" title="HPC-Game"><img class="cover" src="/../cover/HPC-Game0th.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">HPC-Game</div></div></a></div><div class="next-post pull-right"><a href="/2023/12/25/Predicting%20the%20Performance%20of%20Sparse%20Matrix/" title="WISE：Predicting the Performance of Sparse Matrix"><img class="cover" src="/../cover/image-20231223120820448.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">WISE：Predicting the Performance of Sparse Matrix</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/09/11/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/" title="高性能计算学习记录"><img class="cover" src="/../cover/hpc.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-11</div><div class="title">高性能计算学习记录</div></div></a></div><div><a href="/2023/10/13/CMU15-418notes(1-9)/" title="CMU15-418notes(1-9)"><img class="cover" src="/../cover/CMU15-418.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-13</div><div class="title">CMU15-418notes(1-9)</div></div></a></div><div><a href="/2023/10/13/Pthread/" title="Pthreads简记"><img class="cover" src="/../cover/pthread.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-13</div><div class="title">Pthreads简记</div></div></a></div><div><a href="/2023/10/23/CMU15-418notes(10-18)/" title="CMU15-418notes(10-18)"><img class="cover" src="/../cover/CMU15-418.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-23</div><div class="title">CMU15-418notes(10-18)</div></div></a></div><div><a href="/2023/10/27/OpenMP/" title="OpenMP"><img class="cover" src="/../cover/openmp.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-27</div><div class="title">OpenMP</div></div></a></div><div><a href="/2023/10/27/%E8%B6%85%E7%AE%97%E7%AB%9E%E8%B5%9B%E5%AF%BC%E5%BC%95/" title="超算竞赛导引"><img class="cover" src="/../cover/sc.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-27</div><div class="title">超算竞赛导引</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/a0.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">橙</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/A-Y-1"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-1-Introduction"><span class="toc-text">Chapter 1 Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Data-processing-technologies"><span class="toc-text">1.1 Data processing technologies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Comparison-between-ARM-NEON-technology-and-other-implementations"><span class="toc-text">1.2 Comparison between ARM NEON technology and other implementations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Architecture-support-for-NEON-technology"><span class="toc-text">1.3 Architecture support for NEON technology</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-Fundamentals-of-NEON-technology"><span class="toc-text">1.4 Fundamentals of NEON technology</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-2-Compiling-NEON-Instructions"><span class="toc-text">Chapter 2 Compiling NEON Instructions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-3-coding-for-NEON"><span class="toc-text">Chapter 3 coding for NEON</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Overview"><span class="toc-text">3.1 Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Load-and-store-example-RGB-conversion"><span class="toc-text">3.2 Load and store - example RGB conversion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-Load-and-store-data-structures"><span class="toc-text">3.3 Load and store - data structures</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-Load-and-store-leftovers"><span class="toc-text">3.4 Load and store - leftovers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-Permutation-rearranging-vectors"><span class="toc-text">3.5 Permutation - rearranging vectors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-Permutation-NEON-instructions"><span class="toc-text">3.6 Permutation - NEON instructions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-Matrix-multiplication"><span class="toc-text">3.7 Matrix multiplication</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-8-Shifting-left-and-right"><span class="toc-text">3.8 Shifting left and right</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-4-NEON-Intrinsics"><span class="toc-text">Chapter 4 NEON Intrinsics</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Overview"><span class="toc-text">4.1 Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Vector-data-types-for-NEON-intrinsics"><span class="toc-text">4.2 Vector data types for NEON intrinsics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Prototype-of-NEON-Intrinsics"><span class="toc-text">4.3 Prototype of NEON Intrinsics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-Using-NEON-intrinsics"><span class="toc-text">4.4 Using NEON intrinsics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-Variables-and-constants-in-NEON-code"><span class="toc-text">4.5 Variables and constants in NEON code</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-Accessing-vector-types-from-C"><span class="toc-text">4.6 Accessing vector types from C</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-7-Loading-data-from-memory-into-vectors"><span class="toc-text">4.7 Loading data from memory into vectors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-8-Constructing-a-vector-from-a-literal-bit-pattern"><span class="toc-text">4.8 Constructing a vector from a literal bit pattern</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-9-Constructing-multiple-vectors-from-interleaved-memory"><span class="toc-text">4.9  Constructing multiple vectors from interleaved memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-10-Programming-using-NEON-intrinsics"><span class="toc-text">4.10 Programming using NEON intrinsics</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/06/HPC-Game/" title="HPC-Game">HPC-Game</a><time datetime="2024-01-06T04:54:29.000Z" title="发表于 2024-01-06 12:54:29">2024-01-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/02/Neon/" title="NEON编程">NEON编程</a><time datetime="2024-01-02T12:19:29.000Z" title="发表于 2024-01-02 20:19:29">2024-01-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/12/25/Predicting%20the%20Performance%20of%20Sparse%20Matrix/" title="WISE：Predicting the Performance of Sparse Matrix">WISE：Predicting the Performance of Sparse Matrix</a><time datetime="2023-12-25T08:12:14.000Z" title="发表于 2023-12-25 16:12:14">2023-12-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/12/22/Efficiently%20Running%20SpMV%20on%20Long%20Vector%20Architectures/" title="Efficiently Running SpMV on Long Vector Architectures">Efficiently Running SpMV on Long Vector Architectures</a><time datetime="2023-12-22T07:25:14.000Z" title="发表于 2023-12-22 15:25:14">2023-12-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/12/21/CS149-Assignment-4/" title="CS149-Assignment-4(2023FALL)">CS149-Assignment-4(2023FALL)</a><time datetime="2023-12-21T11:54:29.000Z" title="发表于 2023-12-21 19:54:29">2023-12-21</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/../cover/0105.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 橙</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>